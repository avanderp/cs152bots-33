{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO16YNmsJibglmHEQr+PpyP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0f6dfbc804794c899cd04a63374d1a09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a71b2f2d2b64c7f8bad5b0607f687d5","IPY_MODEL_6689d554c6a740d5aeabae858b95ab2e","IPY_MODEL_01aba6cbfd3941e99d7044fd03afdd8e"],"layout":"IPY_MODEL_c97b6114966548f39d5d259798c327cb"}},"1a71b2f2d2b64c7f8bad5b0607f687d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b3732508e6449838d8bda9ed8d66d78","placeholder":"​","style":"IPY_MODEL_75fbbb511ceb4ed3893abf16a1e040f2","value":"Downloading (…)lve/main/config.json: 100%"}},"6689d554c6a740d5aeabae858b95ab2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fca20181e9447e2be67a97df13c075e","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de1c76bd71cb4c6397fc0f2f14fb1424","value":570}},"01aba6cbfd3941e99d7044fd03afdd8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74fb197f74c34c1280650d6b50428ca5","placeholder":"​","style":"IPY_MODEL_7c78c624e9a543e3b73b478fc3324e87","value":" 570/570 [00:00&lt;00:00, 6.77kB/s]"}},"c97b6114966548f39d5d259798c327cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3732508e6449838d8bda9ed8d66d78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75fbbb511ceb4ed3893abf16a1e040f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fca20181e9447e2be67a97df13c075e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1c76bd71cb4c6397fc0f2f14fb1424":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74fb197f74c34c1280650d6b50428ca5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c78c624e9a543e3b73b478fc3324e87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08d460ed5b05417b9cf1fdfd7aab32fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3b032d6911244cd8eddde04ca2a482d","IPY_MODEL_7bf9e3bf9ea542bab45bb9b69c9bf912","IPY_MODEL_c1ecfe6fe36745b6a4387a0b903f40a9"],"layout":"IPY_MODEL_5b5a8b5efb904a46bab97dc2d67dcc02"}},"d3b032d6911244cd8eddde04ca2a482d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ca1d1dc8c9745219f0ab79f01554183","placeholder":"​","style":"IPY_MODEL_5e4a05d79ffd4acbaab08a3e474c2eda","value":"Downloading pytorch_model.bin: 100%"}},"7bf9e3bf9ea542bab45bb9b69c9bf912":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf27b5c4d8db4b5eaaea0a63118fcf71","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d71285a8bf8643c6b76784c7f68a0256","value":440473133}},"c1ecfe6fe36745b6a4387a0b903f40a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01b02adae6b943ceaecebbdd2cee128a","placeholder":"​","style":"IPY_MODEL_5cb985ceeda845d49bc2ddeaf7629fcc","value":" 440M/440M [00:06&lt;00:00, 99.4MB/s]"}},"5b5a8b5efb904a46bab97dc2d67dcc02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ca1d1dc8c9745219f0ab79f01554183":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e4a05d79ffd4acbaab08a3e474c2eda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf27b5c4d8db4b5eaaea0a63118fcf71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d71285a8bf8643c6b76784c7f68a0256":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01b02adae6b943ceaecebbdd2cee128a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cb985ceeda845d49bc2ddeaf7629fcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Generate Sample Predictions\n","Load the open-ai, gpt, and ensemble models to generate predictions over manual examples."],"metadata":{"id":"KHDEFmuzVJGH"}},{"cell_type":"markdown","source":["## Constants and Imports"],"metadata":{"id":"tGwZyEeaWnnB"}},{"cell_type":"code","execution_count":4,"source":["!pip install openai\n","!pip install pytorch-transformers\n","!pip install transformers\n","!pip install nltk\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","!pip install tweet-preprocessor"],"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Collecting aiohttp (from openai)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.22.4)\n","Collecting boto3 (from pytorch-transformers)\n","  Downloading boto3-1.26.146-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.65.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2022.10.31)\n","Collecting sentencepiece (from pytorch-transformers)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacremoses (from pytorch-transformers)\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (16.0.5)\n","Collecting botocore<1.30.0,>=1.29.146 (from boto3->pytorch-transformers)\n","  Downloading botocore-1.29.146-py3-none-any.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-transformers)\n","  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.2.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.146->boto3->pytorch-transformers) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=511d76da0d8795a352331916065bcd0499ee646cecdaef57905873e704f86bd6\n","  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n","Successfully installed boto3-1.26.146 botocore-1.29.146 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.1 sacremoses-0.0.53 sentencepiece-0.1.99\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tweet-preprocessor\n","  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n","Installing collected packages: tweet-preprocessor\n","Successfully installed tweet-preprocessor-0.6.0\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kdxrKb_nUog1","executionInfo":{"status":"ok","timestamp":1685920328991,"user_tz":420,"elapsed":52477,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}},"outputId":"74d08de5-8160-4c6d-b065-f4fc6838f4dd"}},{"cell_type":"code","execution_count":5,"source":["from joblib import load\n","import numpy as np\n","import openai\n","import os\n","import pandas as pd\n","from scipy.special import softmax\n","from sklearn.linear_model import LogisticRegression\n","import time\n","from typing import List"],"outputs":[],"metadata":{"id":"RCtnh0TzYyf3","executionInfo":{"status":"ok","timestamp":1685920328992,"user_tz":420,"elapsed":6,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":6,"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.utils import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import preprocessor as p\n","\n","from transformers import XLMModel, BertTokenizer, BertForSequenceClassification, RobertaTokenizerFast, RobertaForSequenceClassification\n","from transformers import AdamW\n","import nltk\n","from nltk.stem import \tWordNetLemmatizer\n","from nltk.stem.porter import PorterStemmer\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt"],"outputs":[],"metadata":{"id":"KliK0kifYwMF","executionInfo":{"status":"ok","timestamp":1685920350066,"user_tz":420,"elapsed":21079,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":7,"source":["BERT_CHECKPOINT_FILE = \"BERT_base_uncased_best_model.ckpt\"\n","ENSEMBLE_MODEL_FILE = \"'ensemble_model.joblib'\"\n","\n","TRAIN_FILE = \"full_train.csv\" # contains examples that Chat-GPT uses to learn how to predict\n","\n","MAX_LEN = 128 # used for BERT model\n","\n","MAXIMUM_NUM_CHAT_GPT_MESSAGES = 2048 # maximum number of messages\n","NUM_REQUIRED_CHAT_GPT_MESSAGES = 2 # number of structuring messages we must include to Chat-GPT\n","\n","\n","MAX_TRAIN_ROWS = (MAXIMUM_NUM_CHAT_GPT_MESSAGES - NUM_REQUIRED_CHAT_GPT_MESSAGES) // 150\n","\n","\n","ZERO_LABEL_KEYWORD = \"real\"\n","ONE_LABEL_KEYWORD = \"fake\"\n","\n","NO_GPT_PRED_NUM_LABEL = -1"],"outputs":[],"metadata":{"id":"GloZ36u7ZIfw","executionInfo":{"status":"ok","timestamp":1685920350066,"user_tz":420,"elapsed":9,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":8,"source":["# TODO: import these from token.json when we move this notebook to our github code\n","\n","openai.organization = \"REDACTED\"\n","openai.api_key = \"REDACTED\""],"outputs":[],"metadata":{"id":"EcLcmAraqi9r","executionInfo":{"status":"ok","timestamp":1685920350067,"user_tz":420,"elapsed":10,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"markdown","source":["## Mounting Google Drive"],"metadata":{"id":"iyPv_miWHul1"}},{"cell_type":"code","execution_count":9,"source":["GOOGLE_DRIVE_MOUNT_PATH_PREFIX = '/content/drive'\n","MY_CS152_DATA_FILE_PATH = \"drive/MyDrive/Senior/SenSpr/CS152/CS152 Group Project/Milestone 3/Code/Data/\"  # NOTE: you have to modify this to fit wherever the CS152 Group Project/Milestone 3/Code/Data is in your Google Drive"],"outputs":[],"metadata":{"id":"ZXdY2x9CHqgD","executionInfo":{"status":"ok","timestamp":1685920350067,"user_tz":420,"elapsed":9,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":10,"source":["from google.colab import drive\n","drive.mount(GOOGLE_DRIVE_MOUNT_PATH_PREFIX)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19947,"status":"ok","timestamp":1685920370005,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"},"user_tz":420},"id":"0Bvfba5BHwjZ","outputId":"e61b3f32-e60b-4de7-a2f8-7acfcb538cee"}},{"cell_type":"code","execution_count":11,"source":["cd $MY_CS152_DATA_FILE_PATH"],"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Senior/SenSpr/CS152/CS152 Group Project/Milestone 3/Code/Data\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1611,"status":"ok","timestamp":1685920371615,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"},"user_tz":420},"id":"FPRaVNz0Pht8","outputId":"78dc7a4f-5bf4-430c-b483-7c821e26f69d"}},{"cell_type":"markdown","source":["## Loading in Each Model"],"metadata":{"id":"F_k-084qZXra"}},{"cell_type":"markdown","source":["### BERT"],"metadata":{"id":"2Qwpis7MZc-l"}},{"cell_type":"code","execution_count":12,"source":["bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6dfbc804794c899cd04a63374d1a09"},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d460ed5b05417b9cf1fdfd7aab32fa"},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["0f6dfbc804794c899cd04a63374d1a09","1a71b2f2d2b64c7f8bad5b0607f687d5","6689d554c6a740d5aeabae858b95ab2e","01aba6cbfd3941e99d7044fd03afdd8e","c97b6114966548f39d5d259798c327cb","8b3732508e6449838d8bda9ed8d66d78","75fbbb511ceb4ed3893abf16a1e040f2","7fca20181e9447e2be67a97df13c075e","de1c76bd71cb4c6397fc0f2f14fb1424","74fb197f74c34c1280650d6b50428ca5","7c78c624e9a543e3b73b478fc3324e87","08d460ed5b05417b9cf1fdfd7aab32fa","d3b032d6911244cd8eddde04ca2a482d","7bf9e3bf9ea542bab45bb9b69c9bf912","c1ecfe6fe36745b6a4387a0b903f40a9","5b5a8b5efb904a46bab97dc2d67dcc02","4ca1d1dc8c9745219f0ab79f01554183","5e4a05d79ffd4acbaab08a3e474c2eda","cf27b5c4d8db4b5eaaea0a63118fcf71","d71285a8bf8643c6b76784c7f68a0256","01b02adae6b943ceaecebbdd2cee128a","5cb985ceeda845d49bc2ddeaf7629fcc"]},"id":"Gp2ft-MddEGR","executionInfo":{"status":"ok","timestamp":1685920382382,"user_tz":420,"elapsed":10769,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}},"outputId":"5082ebb5-1ccb-4b76-9196-fb5a7e68e97e"}},{"cell_type":"code","execution_count":14,"source":["bert_model.load_state_dict(torch.load(BERT_CHECKPOINT_FILE, map_location=torch.device('cpu')))\n","bert_model.eval()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":14}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VyV9wCr-dT01","executionInfo":{"status":"ok","timestamp":1685920673174,"user_tz":420,"elapsed":10365,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}},"outputId":"1ccf5e4e-01a6-442d-b041-32fa3de1b70a"}},{"cell_type":"markdown","source":["### Chat-GPT"],"metadata":{"id":"kwipzrUbZewk"}},{"cell_type":"markdown","source":["### Ensemble"],"metadata":{"id":"JCbbsaz2Zica"}},{"cell_type":"code","execution_count":29,"source":["ensemble_model = load('ensemble_model.joblib')"],"outputs":[],"metadata":{"id":"SFtwhkq-en4q","executionInfo":{"status":"ok","timestamp":1685920868034,"user_tz":420,"elapsed":185,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"markdown","source":["## Data Preprocessing and Model Application Helper Functions"],"metadata":{"id":"NjdDLYGLZkZF"}},{"cell_type":"markdown","source":["### BERT"],"metadata":{"id":"uXPawUwtfB4M"}},{"cell_type":"code","execution_count":30,"source":["wordnet_lemmatizer = WordNetLemmatizer()\n","porter_stemmer  = PorterStemmer()"],"outputs":[],"metadata":{"id":"fjC8fylufDiV","executionInfo":{"status":"ok","timestamp":1685920868236,"user_tz":420,"elapsed":6,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":31,"source":["p.set_options(p.OPT.URL, p.OPT.EMOJI)\n","\n","def text_preprocess(text, lemmatizer, stemmer):\n","    # text = text.strip('\\xa0')\n","    text = p.clean(text)\n","    tokenization = nltk.word_tokenize(text)     \n","    tokenization = [w for w in tokenization if not w in stop_words]\n","    #   text = ' '.join([porter_stemmer.stem(w) for w in tokenization])\n","    #   text = ' '.join([lemmatizer.lemmatize(w) for w in tokenization])\n","    # text = re.sub(r'\\([0-9]+\\)', '', text).strip()    \n","    return text"],"outputs":[],"metadata":{"id":"rVdg_RCSfPdz","executionInfo":{"status":"ok","timestamp":1685920868236,"user_tz":420,"elapsed":5,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":32,"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"outputs":[],"metadata":{"id":"Q_RfYgynftSx","executionInfo":{"status":"ok","timestamp":1685920868537,"user_tz":420,"elapsed":304,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":33,"source":["def Encode_TextWithAttention(sentence,tokenizer,maxlen,padding_type='max_length',attention_mask_flag=True):\n","    encoded_dict = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=maxlen, truncation=True, padding=padding_type, return_attention_mask=attention_mask_flag)\n","    return encoded_dict['input_ids'],encoded_dict['attention_mask']\n","\n","def Encode_TextWithoutAttention(sentence,tokenizer,maxlen,padding_type='max_length',attention_mask_flag=False):\n","    encoded_dict = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=maxlen, truncation=True, padding=padding_type, return_attention_mask=attention_mask_flag)\n","    return encoded_dict['input_ids']\n","\n","def get_TokenizedTextWithAttentionMask(sentenceList, tokenizer):\n","    token_ids_list,attention_mask_list = [],[]\n","    for sentence in sentenceList:\n","        token_ids,attention_mask = Encode_TextWithAttention(sentence,tokenizer,MAX_LEN)\n","        token_ids_list.append(token_ids)\n","        attention_mask_list.append(attention_mask)\n","    return token_ids_list,attention_mask_list\n","\n","def get_TokenizedText(sentenceList, tokenizer):\n","    token_ids_list = []\n","    for sentence in sentenceList:\n","        token_ids = Encode_TextWithoutAttention(sentence,tokenizer,MAX_LEN)\n","        token_ids_list.append(token_ids)\n","    return token_ids_list"],"outputs":[],"metadata":{"id":"iumSmqyNfuBF","executionInfo":{"status":"ok","timestamp":1685920868537,"user_tz":420,"elapsed":3,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":34,"source":["def bert_preprocess(text_inputs: List, tokenizer = tokenizer, wordnet_lemmatizer = wordnet_lemmatizer, porter_stemmer = porter_stemmer):\n","  preprocessed_texts = []\n","  for text in text_inputs:\n","    preprocessed_texts.append(text_preprocess(text, wordnet_lemmatizer, porter_stemmer))\n","  \n","  token_ids, attention_masks = torch.tensor(get_TokenizedTextWithAttentionMask(preprocessed_texts, tokenizer))\n","\n","  return token_ids, attention_masks"],"outputs":[],"metadata":{"id":"SQCqqbZHgEWg","executionInfo":{"status":"ok","timestamp":1685920868538,"user_tz":420,"elapsed":4,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":55,"source":["def generate_bert_predictions(text_inputs: List, bert_model = bert_model):\n","  # might need to shape into batches\n","  token_ids, attention_masks = bert_preprocess(text_inputs)\n","\n","  output = bert_model(token_ids, token_type_ids=None, attention_mask=attention_masks)\n","  logits = output[0]\n","  \n","  logits = logits.detach().cpu().numpy()\n","  pred = np.argmax(logits, axis=1).flatten()\n","\n","  # check the dimensions to make sure we're doing the right thing\n","  print(logits)\n","  score = torch.sigmoid(torch.tensor(logits)).numpy()[:,1]\n","  print(score)\n","  return pred, score"],"outputs":[],"metadata":{"id":"rzoYEzjWh7qy","executionInfo":{"status":"ok","timestamp":1685921206579,"user_tz":420,"elapsed":150,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"markdown","source":["### Chat-GPT"],"metadata":{"id":"e5n1VBEefEnC"}},{"cell_type":"code","execution_count":36,"source":["train_df = pd.read_csv(TRAIN_FILE)"],"outputs":[],"metadata":{"id":"6PruNb76hS8g","executionInfo":{"status":"ok","timestamp":1685920868746,"user_tz":420,"elapsed":6,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":37,"source":["gpt_messages = [{\"role\": \"system\", \"content\": \"You are a content moderation system. Classify input as either 'real' or 'fake'. Do not use more than one word.\"}]"],"outputs":[],"metadata":{"id":"8fJH-Bdzhl3I","executionInfo":{"status":"ok","timestamp":1685920868747,"user_tz":420,"elapsed":6,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":38,"source":["for index, row in train_df.head(MAX_TRAIN_ROWS).iterrows():\n","  gpt_messages.append({\"role\": \"user\", \"content\": f\"{row['text']}\"})\n","  gpt_messages.append({\"role\": \"assistant\", \"content\": f\"{row['label']}\"})"],"outputs":[],"metadata":{"id":"WOYk9q1ihmcc","executionInfo":{"status":"ok","timestamp":1685920868932,"user_tz":420,"elapsed":191,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":39,"source":["def clean_pred(pred):\n","  if pred == None:\n","    return pred\n","  cleaned = pred.lower()\n","  cleaned = pred.strip()\n","  cleaned = ''.join([i for i in cleaned if i.isalpha()])\n","  return cleaned\n","\n","def assign_label(pred):\n","  if pred == ZERO_LABEL_KEYWORD:\n","    return 0\n","  elif pred == ONE_LABEL_KEYWORD:\n","    return 1\n","  elif pred != None:\n","    return 0.5 \n","  else:  # prediciton was None (gpt response was not correctly produced)\n","    return NO_GPT_PRED_NUM_LABEL"],"outputs":[],"metadata":{"id":"sEv0zRi9kHvd","executionInfo":{"status":"ok","timestamp":1685920868932,"user_tz":420,"elapsed":7,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":40,"source":["def generate_gpt_predictions(text_inputs, prefix_messages = gpt_messages):\n","  preds = []\n","  for input in text_inputs:\n","    messages = prefix_messages[:]\n","    messages.append({\"role\": \"user\", \"content\": f\"{row['text']}\"})  \n","\n","    try:\n","      response = openai.ChatCompletion.create(\n","      model=\"gpt-3.5-turbo\",\n","      messages=messages\n","      )\n","      \n","      preds.append(response['choices'][0]['message']['content'])\n","\n","    except:\n","      preds.append(None)\n","\n","  num_preds = [assign_label(clean_pred(pred)) for pred in preds]\n","  return num_preds"],"outputs":[],"metadata":{"id":"HrVvJH5Dhogc","executionInfo":{"status":"ok","timestamp":1685920868932,"user_tz":420,"elapsed":7,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"markdown","source":["## Ensemble"],"metadata":{"id":"hqFTYGAOk_j1"}},{"cell_type":"code","execution_count":41,"source":["def generate_ensemble_preds_and_scores(text_inputs, ensemble_model = ensemble_model):\n","  bert_preds, bert_scores = generate_bert_predictions(text_inputs)\n","  gpt_preds = generate_gpt_predictions(text_inputs)\n","\n","  ensemble_preds = []\n","  ensemble_scores = []\n","  for idx in range(len(gpt_preds)):\n","    if gpt_preds[idx] == NO_GPT_PRED_NUM_LABEL:\n","      ensemble_preds.append(bert_preds[idx])\n","      ensemble_scores.append(bert_scores[idx])\n","    else:\n","      ensemble_input = np.array([gpt_preds[idx], bert_preds[idx]])\n","      ensemble_preds.append(ensemble_model.predict(X_test))\n","      ensemble_preds.append(ensemble_model.predict_proba(X_test)[:, 1])\n","\n","  return ensemble_preds, ensemble_scores"],"outputs":[],"metadata":{"id":"aYeDyIT4lBIT","executionInfo":{"status":"ok","timestamp":1685920868933,"user_tz":420,"elapsed":7,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"markdown","source":["## Feed in samples"],"metadata":{"id":"JENnGSvuqbB1"}},{"cell_type":"code","execution_count":65,"source":["text_samples_disinfo = [\n","  \"You can cure Covid by injecting bleach, Ivermectin, or Hydroxychloroquine into your bloodstream\",\n","  \"The CDC states that we don’t need to mask after you’ve had COVID-19, as it is no longer contagious\",\n","  \"Some racial groups might be immune to COVID-19\",\n","  \"Joe Biden is lying to us about the severity of the vaccine – he’s just wants more control\",\n","  \"The government is lying to us – COVID-19 does not exist\",\n","  \"Bill Gates is using the vaccine as a vehicle for inserting tracking chips into our bodies\",\n","  \"COVID-19 was definitely made as a bioweapon – we should blame China\"\n","]"],"outputs":[],"metadata":{"id":"qvuFDe_Bqcwl","executionInfo":{"status":"ok","timestamp":1685924181561,"user_tz":420,"elapsed":3,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":43,"source":["non_examples = [\n","  \"CDC data show disproportionate COVID-19 impact in American Indian/Alaska Native populations\",\n","  \"COVID-19 outbreak hits large Bay Area hospital, prompting new mask rules\",\n","  \"The CDC sucks\",\n","  \"Joe Biden should do more to address the pandemic\",\n","  \"It was life as usual for Brittany, who lives in Laurel Hollow, NY. She was taking her pups on a long walk around the block when she started to get an upset stomach. 'I just thought it was anxiety and nerves, since I had just heard the news about coronavirus in New York, so I paid it no mind.'\",\n","]"],"outputs":[],"metadata":{"id":"SVI8PBFoq0bk","executionInfo":{"status":"ok","timestamp":1685920869079,"user_tz":420,"elapsed":5,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}}}},{"cell_type":"code","execution_count":66,"source":["ex_preds, ex_scores = generate_ensemble_preds_and_scores(text_samples_disinfo)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[-4.809136   4.1480427]\n"," [-4.527791   3.9271705]\n"," [-3.565544   2.8630652]\n"," [-4.528927   4.000493 ]\n"," [-5.0487394  4.434396 ]\n"," [-4.909004   4.2238917]\n"," [-5.1625233  4.4584665]]\n","[0.9844503  0.98068124 0.9459901  0.9820225  0.9882768  0.9855698\n"," 0.98855245]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOkxbClvrdoL","executionInfo":{"status":"ok","timestamp":1685924188162,"user_tz":420,"elapsed":5018,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}},"outputId":"68e875d3-e582-4be6-e686-a7eb318ceeee"}},{"cell_type":"code","execution_count":57,"source":["print(ex_preds)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 1, 1, 1, 1, 1]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yiQ5KS2vEfP","executionInfo":{"status":"ok","timestamp":1685921226635,"user_tz":420,"elapsed":3,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}},"outputId":"0a3aa234-98d4-402f-ffba-e373b187ef64"}},{"cell_type":"code","execution_count":61,"source":["non_ex_preds, non_ex_scores = generate_ensemble_preds_and_scores(non_examples)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1.1073209  0.9049733]\n"," [-5.057027   4.410523 ]\n"," [-4.1829567  3.2456396]\n"," [-4.5703564  3.9447515]\n"," [-3.4746425  3.440519 ]]\n","[0.71197045 0.987997   0.9625161  0.9810115  0.9689472 ]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8N3_wxgvHb1","executionInfo":{"status":"ok","timestamp":1685921283879,"user_tz":420,"elapsed":3642,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}},"outputId":"48b96be1-acbc-43d7-bbc3-373095ae3198"}},{"cell_type":"code","execution_count":62,"source":["print(non_ex_preds)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 1, 1, 1]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"423gfekxvJFo","executionInfo":{"status":"ok","timestamp":1685921309170,"user_tz":420,"elapsed":231,"user":{"displayName":"Abigail L VanderPloeg","userId":"12830493961849545419"}},"outputId":"fbc8d6ac-ab47-4465-cdaf-2dd079943ed1"}},{"cell_type":"markdown","source":[],"metadata":{"id":"dYrpHr9tZGQJ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"t9zHohPqUrqn"}}]}